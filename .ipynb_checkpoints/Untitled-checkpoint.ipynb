{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def weight_ones(shape, name):\n",
    "    initial = tf.constant(1.0, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def weight_xavi_init(shape, name):\n",
    "    initial = tf.get_variable(name=name, shape=shape,\n",
    "                              initializer=tf.contrib.layers.xavier_initializer())\n",
    "    return initial\n",
    "\n",
    "\n",
    "def bias_variable(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape, name=name)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    def __init__(self, dropout, image_shape):\n",
    "        \"\"\" We put a few counters to see how many times we called each function \"\"\"\n",
    "        self._dropout_vec = dropout\n",
    "        self._image_shape = image_shape\n",
    "        self._count_conv = 0\n",
    "        self._count_pool = 0\n",
    "        self._count_bn = 0\n",
    "        self._count_activations = 0\n",
    "        self._count_dropouts = 0\n",
    "        self._count_fc = 0\n",
    "        self._count_lstm = 0\n",
    "        self._count_soft_max = 0\n",
    "        self._conv_kernels = []\n",
    "        self._conv_strides = []\n",
    "        self._weights = {}\n",
    "        self._features = {}\n",
    "\n",
    "    \"\"\" Our conv is currently using bias \"\"\"\n",
    "\n",
    "    def conv(self, x, kernel_size, stride, output_size, padding_in='SAME'):\n",
    "        self._count_conv += 1\n",
    "\n",
    "        filters_in = x.get_shape()[-1]\n",
    "        shape = [kernel_size, kernel_size, filters_in, output_size]\n",
    "\n",
    "        weights = weight_xavi_init(shape, 'W_c_' + str(self._count_conv))\n",
    "        bias = bias_variable([output_size], name='B_c_' + str(self._count_conv))\n",
    "\n",
    "        self._weights['W_conv' + str(self._count_conv)] = weights\n",
    "        self._conv_kernels.append(kernel_size)\n",
    "        self._conv_strides.append(stride)\n",
    "\n",
    "        conv_res = tf.add(tf.nn.conv2d(x, weights, [1, stride, stride, 1], padding=padding_in,\n",
    "                                       name='conv2d_' + str(self._count_conv)), bias,\n",
    "                          name='add_' + str(self._count_conv))\n",
    "\n",
    "        self._features['conv_block' + str(self._count_conv - 1)] = conv_res\n",
    "\n",
    "        return conv_res\n",
    "\n",
    "    def max_pool(self, x, ksize=3, stride=2):\n",
    "        self._count_pool += 1\n",
    "        return tf.nn.max_pool(x, ksize=[1, ksize, ksize, 1], strides=[1, stride, stride, 1],\n",
    "                              padding='SAME', name='max_pool' + str(self._count_pool))\n",
    "\n",
    "    def bn(self, x):\n",
    "        self._count_bn += 1\n",
    "        return tf.contrib.layers.batch_norm(x, is_training=False,\n",
    "                                            updates_collections=None,\n",
    "                                            scope='bn' + str(self._count_bn))\n",
    "\n",
    "    def activation(self, x):\n",
    "        self._count_activations += 1\n",
    "        return tf.nn.relu(x, name='relu' + str(self._count_activations))\n",
    "\n",
    "    def dropout(self, x):\n",
    "        print(\"Dropout\", self._count_dropouts)\n",
    "        self._count_dropouts += 1\n",
    "        output = tf.nn.dropout(x, self._dropout_vec[self._count_dropouts - 1],\n",
    "                               name='dropout' + str(self._count_dropouts))\n",
    "\n",
    "        return output\n",
    "\n",
    "    def fc(self, x, output_size):\n",
    "        self._count_fc += 1\n",
    "        filters_in = x.get_shape()[-1]\n",
    "        shape = [filters_in, output_size]\n",
    "\n",
    "        weights = weight_xavi_init(shape, 'W_f_' + str(self._count_fc))\n",
    "        bias = bias_variable([output_size], name='B_f_' + str(self._count_fc))\n",
    "\n",
    "        return tf.nn.xw_plus_b(x, weights, bias, name='fc_' + str(self._count_fc))\n",
    "\n",
    "    def conv_block(self, x, kernel_size, stride, output_size, padding_in='SAME'):\n",
    "        print(\" === Conv\", self._count_conv, \"  :  \", kernel_size, stride, output_size)\n",
    "        with tf.name_scope(\"conv_block\" + str(self._count_conv)):\n",
    "            x = self.conv(x, kernel_size, stride, output_size, padding_in=padding_in)\n",
    "            x = self.bn(x)\n",
    "            x = self.dropout(x)\n",
    "\n",
    "            return self.activation(x)\n",
    "\n",
    "    def fc_block(self, x, output_size):\n",
    "        print(\" === FC\", self._count_fc, \"  :  \", output_size)\n",
    "        with tf.name_scope(\"fc\" + str(self._count_fc + 1)):\n",
    "            x = self.fc(x, output_size)\n",
    "            x = self.dropout(x)\n",
    "            self._features['fc_block' + str(self._count_fc + 1)] = x\n",
    "            return self.activation(x)\n",
    "\n",
    "    def get_weigths_dict(self):\n",
    "        return self._weights\n",
    "\n",
    "    def get_feat_tensors_dict(self):\n",
    "        return self._features\n",
    "\n",
    "\n",
    "def load_imitation_learning_network(input_image, input_data, input_size, dropout):\n",
    "    branches = []\n",
    "\n",
    "    x = input_image\n",
    "\n",
    "    network_manager = Network(dropout, tf.shape(x))\n",
    "\n",
    "    \"\"\"conv1\"\"\"  # kernel sz, stride, num feature maps\n",
    "    xc = network_manager.conv_block(x, 5, 2, 32, padding_in='VALID')\n",
    "    print(xc)\n",
    "    xc = network_manager.conv_block(xc, 3, 1, 32, padding_in='VALID')\n",
    "    print(xc)\n",
    "\n",
    "    \"\"\"conv2\"\"\"\n",
    "    xc = network_manager.conv_block(xc, 3, 2, 64, padding_in='VALID')\n",
    "    print(xc)\n",
    "    xc = network_manager.conv_block(xc, 3, 1, 64, padding_in='VALID')\n",
    "    print(xc)\n",
    "\n",
    "    \"\"\"conv3\"\"\"\n",
    "    xc = network_manager.conv_block(xc, 3, 2, 128, padding_in='VALID')\n",
    "    print(xc)\n",
    "    xc = network_manager.conv_block(xc, 3, 1, 128, padding_in='VALID')\n",
    "    print(xc)\n",
    "\n",
    "    \"\"\"conv4\"\"\"\n",
    "    xc = network_manager.conv_block(xc, 3, 1, 256, padding_in='VALID')\n",
    "    print(xc)\n",
    "    xc = network_manager.conv_block(xc, 3, 1, 256, padding_in='VALID')\n",
    "    print(xc)\n",
    "    \"\"\"mp3 (default values)\"\"\"\n",
    "\n",
    "    \"\"\" reshape \"\"\"\n",
    "    x = tf.reshape(xc, [-1, int(np.prod(xc.get_shape()[1:]))], name='reshape')\n",
    "    print(x)\n",
    "\n",
    "    \"\"\" fc1 \"\"\"\n",
    "    x = network_manager.fc_block(x, 512)\n",
    "    print(x)\n",
    "    \"\"\" fc2 \"\"\"\n",
    "    x = network_manager.fc_block(x, 512)\n",
    "\n",
    "    \"\"\"Process Control\"\"\"\n",
    "\n",
    "    \"\"\" Speed (measurements)\"\"\"\n",
    "    with tf.name_scope(\"Speed\"):\n",
    "        speed = input_data[1]  # get the speed from input data\n",
    "        speed = network_manager.fc_block(speed, 128)\n",
    "        speed = network_manager.fc_block(speed, 128)\n",
    "\n",
    "    \"\"\" Joint sensory \"\"\"\n",
    "    j = tf.concat([x, speed], 1)\n",
    "    j = network_manager.fc_block(j, 512)\n",
    "\n",
    "    \"\"\"Start BRANCHING\"\"\"\n",
    "    branch_config = [[\"Steer\", \"Gas\", \"Brake\"], [\"Steer\", \"Gas\", \"Brake\"], \\\n",
    "                     [\"Steer\", \"Gas\", \"Brake\"], [\"Steer\", \"Gas\", \"Brake\"], [\"Speed\"]]\n",
    "\n",
    "    for i in range(0, len(branch_config)):\n",
    "        with tf.name_scope(\"Branch_\" + str(i)):\n",
    "            if branch_config[i][0] == \"Speed\":\n",
    "                # we only use the image as input to speed prediction\n",
    "                branch_output = network_manager.fc_block(x, 256)\n",
    "                branch_output = network_manager.fc_block(branch_output, 256)\n",
    "            else:\n",
    "                branch_output = network_manager.fc_block(j, 256)\n",
    "                branch_output = network_manager.fc_block(branch_output, 256)\n",
    "\n",
    "            branches.append(network_manager.fc(branch_output, len(branch_config[i])))\n",
    "\n",
    "        print(branch_output)\n",
    "\n",
    "    return branches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Failed to convert object of type <class 'tuple'> to Tensor. Contents: (None, 88, 200, 3). Consider casting elements to a supported type.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m       \u001b[0mstr_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mproto_values\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_bytes\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m     60\u001b[0m     raise TypeError('Expected binary or unicode string, got %r' %\n\u001b[1;32m---> 61\u001b[1;33m                     (bytes_or_text,))\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Expected binary or unicode string, got None",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-555fda771f57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mtarget_controller\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"target_control\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mnetwork_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_imitation_learning_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mnetwork_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-e160c4b49bb3>\u001b[0m in \u001b[0;36mload_imitation_learning_network\u001b[1;34m(input_image, input_data, input_size, dropout)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mnetwork_manager\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;34m\"\"\"conv1\"\"\"\u001b[0m  \u001b[1;31m# kernel sz, stride, num feature maps\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape\u001b[1;34m(input, name, out_type)\u001b[0m\n\u001b[0;32m    217\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mout_type\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m   \"\"\"\n\u001b[1;32m--> 219\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mshape_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    220\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\u001b[0m in \u001b[0;36mshape_internal\u001b[1;34m(input, name, optimize, out_type)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_fully_defined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, preferred_dtype)\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m       \u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpreferred_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1011\u001b[1;33m       as_ref=False)\n\u001b[0m\u001b[0;32m   1012\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1013\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, ctx)\u001b[0m\n\u001b[0;32m   1105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m       \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[1;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[0;32m    215\u001b[0m                                          as_ref=False):\n\u001b[0;32m    216\u001b[0m   \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name, verify_shape)\u001b[0m\n\u001b[0;32m    194\u001b[0m   tensor_value.tensor.CopyFrom(\n\u001b[0;32m    195\u001b[0m       tensor_util.make_tensor_proto(\n\u001b[1;32m--> 196\u001b[1;33m           value, dtype=dtype, shape=shape, verify_shape=verify_shape))\n\u001b[0m\u001b[0;32m    197\u001b[0m   \u001b[0mdtype_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAttrValue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensor_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m   const_tensor = g.create_op(\n",
      "\u001b[1;32mc:\\users\\overlapjho\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_util.py\u001b[0m in \u001b[0;36mmake_tensor_proto\u001b[1;34m(values, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    523\u001b[0m       raise TypeError(\"Failed to convert object of type %s to Tensor. \"\n\u001b[0;32m    524\u001b[0m                       \u001b[1;34m\"Contents: %s. Consider casting elements to a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m                       \"supported type.\" % (type(values), values))\n\u001b[0m\u001b[0;32m    526\u001b[0m     \u001b[0mtensor_proto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_val\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtensor_proto\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Failed to convert object of type <class 'tuple'> to Tensor. Contents: (None, 88, 200, 3). Consider casting elements to a supported type."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "dropoutVec = [1.0] * 8 + [0.7] * 2 + [0.5] * 2 + [0.5] * 1 + [0.5, 1.] * 5\n",
    "branch_config = [\n",
    "                    [\"Steer\", \"Gas\", \"Brake\"], [\"Steer\", \"Gas\", \"Brake\"], \n",
    "                    [\"Steer\", \"Gas\", \"Brake\"], [\"Steer\", \"Gas\", \"Brake\"],\n",
    "                    [\"Speed\"] \n",
    "              ]\n",
    "\n",
    "_image_size = (88, 200, 3)\n",
    "\n",
    "self.image_size = tf.placeholder(\"float\", shape=[None, _image_size[0],\n",
    "                                                                _image_size[1],\n",
    "                                                                _image_size[2]],\n",
    "                                                name=\"input_image\")\n",
    "dout = tf.placeholder(\"float\", shape=[len(dropoutVec)])\n",
    "input_image = (None, image_size[0], image_size[1], image_size[2] )\n",
    "\n",
    "input_data = []\n",
    "\n",
    "input_data.append(tf.placeholder(tf.float32, shape=[None, 4], name=\"input_control\"))\n",
    "\n",
    "input_data.append(tf.placeholder(tf.float32, shape=[None, 1], name=\"input_speed\"))\n",
    "\n",
    "target_speed = tf.placeholder(tf.float32, shape=[None, 1], name=\"target_speed\")\n",
    "\n",
    "target_controller = tf.placeholder(tf.float32, shape=[None, 3], name=\"target_control\")\n",
    "\n",
    "network_tensor = load_imitation_learning_network(input_image, input_data, image_size,dout)\n",
    "\n",
    "network_tensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
